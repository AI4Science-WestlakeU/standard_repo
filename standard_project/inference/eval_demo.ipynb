{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "except:\n",
    "    pass\n",
    "# general package\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import tqdm\n",
    "from einops import rearrange, repeat\n",
    "import logging\n",
    "import datetime  \n",
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import datasets \n",
    "import numpy as np\n",
    "#custom package, model,data,utils\n",
    "from src.data.data_demo import Advection\n",
    "from src.model.model_demo import Net_demo\n",
    "from src.utils.utils import set_seed,caculate_confidence_interval\n",
    "# path\n",
    "from src.filepath import EXP_PATH,SRC_PATH,PARENT_WP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Training Configurations of autoencoder fot theory\")\n",
    "parser.add_argument(\"--date_exp\", type=str, default=\"2021-09-30\", help=\"Date of the experiment\")\n",
    "parser.add_argument(\"--exp_name\", type=str, default=\"AE_overfit\", help=\"Name of the experiment\")\n",
    "parser.add_argument(\"--dataset_path\", type=str, default=\"data\", help=\"Path to the data\")\n",
    "parser.add_argument(\"--results_path\", type=str, default=\"results\", help=\"Path to the results\")\n",
    "parser.add_argument('--config', type=str, default='/project_module/configs/config.yaml')\n",
    "\n",
    "\n",
    "# evaluation configurations\n",
    "parser.add_argument(\"--eval_batch_size\", type=int, default=256, help=\"eval Batch size\")\n",
    "parser.add_argument(\"--checkpoint_path\", type=str, default=None, help=\"Path load the checkpoint to restore, if not None, contine training\")\n",
    "\n",
    "\n",
    "parser.add_argument(\"--gpu_id\", type=int, default=0, help=\"ID of the GPU\")\n",
    "parser.add_argument(\"--seed\", type=int, default=0, help=\"Seed for the random number generator\")\n",
    "\n",
    "# model configurations\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.date_exp=\"2024-08-05\"\n",
    "args.exp_name=\"eval_demo_test\"\n",
    "args.config = \"standard_repo/results/2024-08-05/taining_demo/config.yaml\"\n",
    "\n",
    "args.dataset_path =\"standard_repo/dataset/advection\"\n",
    "# training configurations\n",
    "args.eval_batch_size = 512\n",
    "\n",
    "# configure environment\n",
    "args.gpu_id = 0\n",
    "args.seed = 42\n",
    "\n",
    "\n",
    "args.config = os.path.join(PARENT_WP,args.config)\n",
    "if args.config!=None:\n",
    "    with open(args.config, 'r') as file:\n",
    "        config_data = yaml.safe_load(file)\n",
    "\n",
    "    # 更新 args\n",
    "    for key, value in config_data.items():\n",
    "        try:\n",
    "            setattr(args, key, value)\n",
    "        except:\n",
    "            pass\n",
    "args.checkpoint_path = \"standard_repo/results/2024-08-05/taining_demo/model_epoch_20.pth\"\n",
    "args.checkpoint_path = os.path.join(PARENT_WP,args.checkpoint_path)   \n",
    "# set up logging\n",
    "current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "log_filename = os.path.join(args.results_path, \"evaluation_{}.log\".format(current_time))\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info('args: {}'.format(args))\n",
    "# set device and seed\n",
    "device = torch.device(\"cuda:\"+str(args.gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and Cingure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "eval_dataset = Advection(\n",
    "        dataset_name=\"Advection\",\n",
    "        dataset_path=args.dataset_path,\n",
    "        mode = 'test',\n",
    "        input_steps=1,\n",
    "        output_steps=80,\n",
    "        time_interval=1,\n",
    "        simutime_steps=80,\n",
    "        rescaler=4,\n",
    "    )\n",
    "eval_dataloader = torch.utils.data.DataLoader(eval_dataset,batch_size= args.eval_batch_size, shuffle=False, pin_memory=True,num_workers=8)\n",
    "logging.info(f\"data loaded from{args.dataset_path}\")\n",
    "\n",
    "# configure model\n",
    "model = Net_demo().to(device)\n",
    "if args.checkpoint_path is not None:\n",
    "    model.load_state_dict(torch.load(args.checkpoint_path))\n",
    "    logging.info(f\"Checkpoint{args.checkpoint_path} loaded\")\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Start evaluate on \",torch.cuda.get_device_name())\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "logging.info(\"Number of parameters: {}\".format(num_params))\n",
    "start_time = time.time()\n",
    "bs= args.eval_batch_size\n",
    "with torch.no_grad():\n",
    "    for eval_data in eval_dataloader:\n",
    "        break\n",
    "    input,target = eval_data\n",
    "    input = input.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(input) # [B,1,T,s] => [B,1,T,s]\n",
    "end_time = time.time()\n",
    "relative_mse =torch.norm(target- output) / torch.norm(target)\n",
    "target = target.reshape(bs,-1)\n",
    "output = output.reshape(bs,-1)\n",
    "mse_bach = ((target-output)**2).mean(-1) #[B,]\n",
    "mean,std_dev,margin_of_error,min_value=caculate_confidence_interval(mse_bach)\n",
    "logging.info(\"Evaluate the checkpoint: {}\".format(args.checkpoint_path))\n",
    "logging.info(\"Relative MSE: {:.8f}\".format(relative_mse))\n",
    "logging.info(\"MSE: {:.8f}\".format(mean))\n",
    "logging.info(\"MSE std: {:.8f}\".format(std_dev))\n",
    "logging.info(\"MSE margin of error: {:.8f}\".format(margin_of_error))\n",
    "logging.info(f\"Evaulation complete, time cost is {end_time-start_time}s\")\n",
    "logging.info(\"Results save at {}\".format(args.results_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
