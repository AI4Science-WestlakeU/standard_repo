{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "except:\n",
    "    pass\n",
    "# general package\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import tqdm\n",
    "from einops import rearrange, repeat\n",
    "import logging\n",
    "import datetime  \n",
    "import time\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import datasets \n",
    "import numpy as np\n",
    "#custom package\n",
    "from src.data.data_demo import Advection\n",
    "from src.model.model_demo import Net_demo\n",
    "from src.utils.utils import set_seed,draw_loss,add_args_from_config,save_config_from_args\n",
    "# path\n",
    "from src.filepath import EXP_PATH,SRC_PATH,PARENT_WP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Training Configurations of autoencoder fot theory\")\n",
    "parser.add_argument(\"--date_exp\", type=str, default=\"2021-09-30\", help=\"Date of the experiment\")\n",
    "parser.add_argument(\"--exp_name\", type=str, default=\"AE_overfit\", help=\"Name of the experiment\")\n",
    "parser.add_argument(\"--dataset_path\", type=str, default=\"data\", help=\"Path to the data\")\n",
    "parser.add_argument(\"--results_path\", type=str, default=\"results\", help=\"Path to the results\")\n",
    "parser.add_argument('--config', type=str, default='/project_module/configs/config.yaml')\n",
    "\n",
    "\n",
    "# training configurations\n",
    "parser.add_argument(\"--epochs\", type=int, default=100, help=\"Number of epochs\")\n",
    "parser.add_argument(\"--save_every\", type=int, default=20, help=\"Save the model every x epochs\")\n",
    "parser.add_argument(\"--train_batch_size\", type=int, default=256, help=\"Batch size\")\n",
    "parser.add_argument(\"--test_batch_size\", type=int, default=256, help=\"test Batch size\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.001, help=\"Learning rate\")\n",
    "parser.add_argument(\"--checkpoint_path\", type=str, default=None, help=\"Path load the checkpoint to restore, if not None, contine training\")\n",
    "parser.add_argument(\"--num_workers\", type=int, default=0, help=\"Number of workers for the dataloader\")\n",
    "\n",
    "parser.add_argument(\"--gpu_id\", type=int, default=0, help=\"ID of the GPU\")\n",
    "parser.add_argument(\"--seed\", type=int, default=0, help=\"Seed for the random number generator\")\n",
    "\n",
    "# model configurations\n",
    "\n",
    "try:\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    args = parser.parse_args([])\n",
    "\n",
    "    args.date_exp=\"2024-08-05\"\n",
    "    args.exp_name=\"taining_demo\"\n",
    "    args.config = \"standard_repo/src/configs/config.yaml\"\n",
    "\n",
    "    args.dataset_path =\"standard_repo/dataset/advection\"\n",
    "    # training configurations\n",
    "    args.epochs = 100\n",
    "    args.save_every = 10\n",
    "    args.train_batch_size = 512\n",
    "    args.test_batch_size = 512\n",
    "    args.lr = 0.001\n",
    "    args.checkpoint_path = None\n",
    "    args.num_workers = 0\n",
    "\n",
    "    # configure environment\n",
    "    args.gpu_id = 0\n",
    "    args.seed = 42\n",
    "\n",
    "\n",
    "except:\n",
    "    # parser = add_args_from_config(parser)\n",
    "    args=parser.parse_args()\n",
    "    if args.config!=None:\n",
    "        with open(args.config, 'r') as file:\n",
    "            config_data = yaml.safe_load(file)\n",
    "\n",
    "        # 更新 args\n",
    "        for key, value in config_data.items():\n",
    "            setattr(args, key, value)\n",
    "    is_jupyter = False\n",
    "\n",
    "# prepare t path\n",
    "args.results_path=EXP_PATH+\"/results/\"+args.date_exp+\"/\"+args.exp_name+\"/\"\n",
    "args.dataset_path = os.path.join(PARENT_WP,args.dataset_path)\n",
    "args.config = os.path.join(PARENT_WP,args.config)\n",
    "\n",
    "if args.checkpoint_path != None:\n",
    "    args.checkpoint_path = os.path.join(PARENT_WP,args.checkpoint_path)\n",
    "if not os.path.exists(args.results_path):\n",
    "    os.makedirs(args.results_path)\n",
    "save_config_from_args(args)\n",
    "# set up logging\n",
    "current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "log_filename = os.path.join(args.results_path, \"training_{}.log\".format(current_time))\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO,\n",
    "                        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info('args: {}'.format(args))\n",
    "# set device and seed\n",
    "device = torch.device(\"cuda:\"+str(args.gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
    "set_seed(args.seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(dl):\n",
    "    while True:\n",
    "        for data in dl:\n",
    "            yield data\n",
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and initialize model, model optimizer, loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train_dataset = Advection(\n",
    "        dataset_name=\"Advection\",\n",
    "        dataset_path=args.dataset_path,\n",
    "        mode = 'train',\n",
    "\n",
    "        input_steps=1,\n",
    "        output_steps=80,\n",
    "        time_interval=1,\n",
    "        simutime_steps=80,\n",
    "        rescaler=4,\n",
    "    )\n",
    "test_dataset = Advection(\n",
    "        dataset_name=\"Advection\",\n",
    "        dataset_path=args.dataset_path,\n",
    "        mode = 'test',\n",
    "        input_steps=1,\n",
    "        output_steps=80,\n",
    "        time_interval=1,\n",
    "        simutime_steps=80,\n",
    "        rescaler=4,\n",
    "    )\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size= args.train_batch_size, shuffle=True, pin_memory=True,num_workers=args.num_workers)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, pin_memory=True,num_workers=args.num_workers)\n",
    "logging.info(f\"data loaded from{args.dataset_path}\")\n",
    "\n",
    "# configure model\n",
    "model = Net_demo().to(device)\n",
    "if args.checkpoint_path is not None:\n",
    "    model.load_state_dict(torch.load(args.checkpoint_path))\n",
    "    logging.info(f\"Checkpoint{args.checkpoint_path} loaded\")\n",
    "\n",
    "# configue optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Start training on \",torch.cuda.get_device_name())\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "logging.info(\"Number of parameters: {}\".format(num_params))\n",
    "logging.info(\"number of batch in train_loader: \", len(train_dataloader))\n",
    "print(\"number of batch in test_loader: \", len(test_dataloader))\n",
    "start_time = time.time()\n",
    "training_loss_list = []\n",
    "test_loss_list = []\n",
    "best_epoch = 0\n",
    "\n",
    "# training loop\n",
    "for epoch in tqdm.tqdm(range(1,args.epochs+1)):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    best_test_loss = 1e9\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "        input,target = data\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input) # [B,1,T,s] => [B,1,T,s]\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.sum().item()\n",
    "        # input = input.cpu()\n",
    "        # target = target.cpu()\n",
    "        torch.cuda.empty_cache()\n",
    "    scheduler.step()\n",
    "    \n",
    "    average_loss = total_loss/len(train_dataloader)\n",
    "    training_loss_list.append(average_loss)\n",
    "    logging.info(\"training epoch {}, average loss: {}\".format(epoch, average_loss))\n",
    "    if epoch % args.save_every == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for test_data in test_dataloader:\n",
    "                break\n",
    "            input,target = test_data\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input) # [B,1,T,s] => [B,1,T,s]\n",
    "            loss = criterion(output, target)\n",
    "            test_loss = loss.sum().item()\n",
    "            test_loss_list.append(test_loss)\n",
    "            if test_loss< best_test_loss:\n",
    "                best_epoch = epoch\n",
    "                best_test_loss = test_loss\n",
    "            logging.info(\"testing epoch {}, loss: {}\".format(epoch, test_loss))\n",
    "        torch.save(model.state_dict(), os.path.join(args.results_path, \"model_epoch_{}.pth\".format(epoch)))\n",
    "        draw_loss(training_loss_list,test_loss_list,args.results_path)\n",
    "end_time = time.time()\n",
    "logging.info(f\"Training complete, best epoch is {best_epoch}, time cost is {end_time-start_time}s\")\n",
    "logging.info(\"Results save at {}\".format(args.results_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciDisc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
